{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8kFbg3Vjxjm"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(\"heavy_makeup_CelebA.zip\",\"r\") as zip_file:\n",
        "  zip_file.extractall(\"heavy_makeup_CelebA\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "  def __init__(self, root, train, transform=None):\n",
        "\n",
        "    if train:\n",
        "      image_root = Path(root) / \"train\"\n",
        "    else:\n",
        "      image_root = Path(root) / \"val\"\n",
        "\n",
        "    with open(Path(root) / \"classnames.txt\", \"r\") as f:\n",
        "      lines = f.readlines()\n",
        "      self.classes = [line.strip() for line in lines]\n",
        "\n",
        "    self.paths = [i for i in image_root.rglob(\"*\") if i.is_file()]\n",
        "    self.transform = transform\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    img = Image.open(self.paths[index]).convert(\"RGB\")\n",
        "    class_name = self.paths[index].parent.name\n",
        "    class_idx = self.classes.index(class_name)\n",
        "\n",
        "    if self.transform:\n",
        "      return self.transform(img), class_idx\n",
        "    else:\n",
        "      return img, class_idx\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.paths)"
      ],
      "metadata": {
        "id": "ry9ihMUFj0hW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose([\n",
        "  transforms.Resize((64, 64)),\n",
        "  transforms.TrivialAugmentWide(),\n",
        "  transforms.ToTensor()\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "  transforms.Resize((64, 64)),\n",
        "  transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "GYsRgB_Sj5xq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[:1][0].shape"
      ],
      "metadata": {
        "id": "d0BtRdI7zA_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = ImageDataset(root=\"heavy_makeup_CelebA/heavy_makeup_CelebA\",\n",
        "                train=True,\n",
        "                transform=train_transforms\n",
        ")\n",
        "\n",
        "test_dataset = ImageDataset(root=\"heavy_makeup_CelebA/heavy_makeup_CelebA\",\n",
        "                train=False,\n",
        "                transform=test_transforms\n",
        ")"
      ],
      "metadata": {
        "id": "nUBhiKjukACV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c,e = train_dataset[0]\n",
        "c.shape,e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnWt0gJnoI2v",
        "outputId": "58475d3e-a585-479e-fa1e-8e32069cc9b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 64, 64]), 1)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_dataset,\n",
        "                batch_size=BATCH_SIZE,\n",
        "                shuffle=True\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(dataset=test_dataset,\n",
        "                batch_size=BATCH_SIZE,\n",
        "                shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "5A0EzQfMkAZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w, z = next(iter(train_dataloader))\n",
        "w[:1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6pWlN4Blv64",
        "outputId": "3aba8c13-ee17-467e-cb41-fa2f22bae6a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 64, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "class ImageClassificationModel3(nn.Module):\n",
        "  def __init__(self, input_shape, output_shape):\n",
        "    super().__init__()\n",
        "    self.conv_block_1 = nn.Sequential(\n",
        "      nn.Conv2d(in_channels=input_shape,\n",
        "          out_channels=8,\n",
        "          kernel_size=(3, 3),\n",
        "          stride=1,\n",
        "          padding=1\n",
        "      ),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(in_channels=8,\n",
        "          out_channels=8,\n",
        "          kernel_size=(3, 3),\n",
        "          stride=1,\n",
        "          padding=1\n",
        "      ),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=(2, 2),\n",
        "            stride=2,\n",
        "            padding=0\n",
        "      )\n",
        "    )\n",
        "\n",
        "    self.conv_block_2 = nn.Sequential(\n",
        "      nn.Conv2d(in_channels=8,\n",
        "          out_channels=16,\n",
        "          kernel_size=(3, 3),\n",
        "          stride=1,\n",
        "          padding=1\n",
        "      ),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(in_channels=16,\n",
        "          out_channels=16,\n",
        "          kernel_size=(3, 3),\n",
        "          stride=1,\n",
        "          padding=1\n",
        "      ),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=(2, 2),\n",
        "            stride=2,\n",
        "            padding=0\n",
        "      )\n",
        "    )\n",
        "\n",
        "    self.classifier = nn.Sequential(\n",
        "      nn.Flatten(start_dim=1, end_dim=-1),\n",
        "      nn.Linear(in_features=16*16*16, out_features=1),\n",
        "      nn.Sigmoid()\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    x = self.conv_block_1(x)\n",
        "    x = self.conv_block_2(x)\n",
        "    x = self.classifier(x)\n",
        "    return x\n",
        "\n",
        "#nn.BatchNorm2d(通道數)，通常在激活函數之前"
      ],
      "metadata": {
        "id": "eHKE9mg1kEU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "IoFtEI-8kLQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(87)\n",
        "model = ImageClassificationModel3(3, 1)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "4Oy7952BkLLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "j =model(w)\n",
        "j"
      ],
      "metadata": {
        "id": "9t70sT25o5Wu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cost_fn = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "FBzn2VMIkNBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(dataloader, model, cost_fn, optimizer, accuracy_fn, device):\n",
        "  train_cost = 0\n",
        "  train_acc = 0\n",
        "  for batch, (x, y) in enumerate(dataloader):\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    y = torch.unsqueeze(y, dim=1)\n",
        "    y = y.float()\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    y_pred = model(x)\n",
        "\n",
        "    cost = cost_fn(y_pred, y)\n",
        "\n",
        "    train_cost += cost\n",
        "    train_acc += accuracy_fn(y_pred, y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    cost.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "  train_cost /= len(train_dataloader)\n",
        "  train_acc /= len(train_dataloader)\n",
        "\n",
        "  print(f\"\\nTrain Cost: {train_cost:.4f}, Train Acc: {train_acc:.2f}\")\n",
        "\n",
        "\n",
        "def test_step(dataloader, model, cost_fn, accuracy_fn, device):\n",
        "  test_cost = 0\n",
        "  test_acc = 0\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for x, y in dataloader:\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      y = torch.unsqueeze(y, dim=1)\n",
        "      y = y.float()\n",
        "\n",
        "      test_pred = model(x)\n",
        "\n",
        "      test_cost += cost_fn(test_pred, y)\n",
        "      test_acc += accuracy_fn(test_pred, y)\n",
        "\n",
        "    test_cost /= len(test_dataloader)\n",
        "    test_acc /= len(test_dataloader)\n",
        "\n",
        "  print(f\"Test Cost: {test_cost:.4f}, Test Acc: {test_acc:.2f} \\n\")"
      ],
      "metadata": {
        "id": "xE_1Rfy-kOpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_fn(y_pred, y_true):\n",
        "\n",
        "  acc = (torch.round(y_pred)==y_true).sum() / len(y_true) * 100\n",
        "\n",
        "  return acc"
      ],
      "metadata": {
        "id": "cr4FpduKmO6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "epochs = 30\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epoch}\\n-------\")\n",
        "\n",
        "  train_step(train_dataloader, model, cost_fn, optimizer, accuracy_fn, device)\n",
        "\n",
        "  test_step(test_dataloader, model, cost_fn, accuracy_fn, device)\n"
      ],
      "metadata": {
        "id": "iXJdRerkkR8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(obj=model.state_dict(), f=\"model/pytorch_linear_regression_2.pth\")\n",
        "model.state_dict()"
      ],
      "metadata": {
        "id": "V-Mcm1_WNZem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = ImageClassificationModel3(28*28,10)\n",
        "\n",
        "model2.load_state_dict(torch.load(f=\"model/pytorch_linear_regression_2.pth\"))\n",
        "model2.state_dict()"
      ],
      "metadata": {
        "id": "sr5dtHABNZ29"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}